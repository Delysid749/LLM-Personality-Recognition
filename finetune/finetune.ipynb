{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
    "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
    "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    # Can select any from the below:\n",
    "    # \"unsloth/Qwen2.5-0.5B\", \"unsloth/Qwen2.5-1.5B\", \"unsloth/Qwen2.5-3B\"\n",
    "    # \"unsloth/Qwen2.5-14B\",  \"unsloth/Qwen2.5-32B\",  \"unsloth/Qwen2.5-72B\",\n",
    "    # And also all Instruct versions and Math. Coding verisons!\n",
    "    model_name = \"unsloth/Qwen2.5-7B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ],
   "id": "46a7691c3befe22d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ],
   "id": "87710f422980e407"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:09:08.738122Z",
     "start_time": "2025-03-20T14:00:07.042990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
    "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "\n",
    "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
    "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
    "\n",
    "    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ],
   "id": "bc546c2bcf365ee5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19389\\.conda\\envs\\finetune\\lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Laptop GPU. Num GPUs = 1. Max memory: 7.996 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b17a5202b3574d07bf7e18e5d9b31e44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee842ccc18864770a27dee2003babb6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a9f4bbb74b442a7aa41350bdba0441b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3090f46f6c0c40f5a88787f97e5cf8bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e26556683ac44a7dbced1acc01612dee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:09:11.208292Z",
     "start_time": "2025-03-20T14:09:08.741705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ],
   "id": "2cd4d9eb200769e0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.14 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:09:12.220590Z",
     "start_time": "2025-03-20T14:09:11.411690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "alpaca_prompt = \"\"\"\n",
    "### Instruction:\n",
    "# è§’è‰²\n",
    "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
    "\n",
    "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
    "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
    "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
    "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
    "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
    "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
    "\n",
    "## é™åˆ¶\n",
    "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "def formatting_prompts_func(examples):\n",
    "    # instructions = examples[\"introduction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for input_data, output in zip(inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = alpaca_prompt.format(input_data, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "from datasets import load_dataset,DatasetDict\n",
    "dataset = load_dataset(\"json\", data_files=\"../data/results.jsonl\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "full_dataset = dataset[\"train\"]  # æå–å®é™…æ•°æ®éƒ¨åˆ†\n",
    "# ç›´æ¥åˆ’åˆ†ï¼š90% è®­ç»ƒï¼Œ10% æµ‹è¯•\n",
    "train_test = full_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "# ç»„åˆä¸º DatasetDict\n",
    "final_dataset = DatasetDict({\n",
    "    \"train\": train_test[\"train\"],\n",
    "    \"test\": train_test[\"test\"],\n",
    "})\n",
    "# æŸ¥çœ‹åˆ’åˆ†ç»“æœ\n",
    "print(final_dataset)"
   ],
   "id": "e189ff99fca5b210",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ba7b24e6f5a45faa4982c63d8d588b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['introduction', 'input', 'output', 'text'],\n",
      "        num_rows: 72\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['introduction', 'input', 'output', 'text'],\n",
      "        num_rows: 8\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:09:18.682446Z",
     "start_time": "2025-03-20T14:09:12.252855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prrompt = f\"{final_dataset['test'][0]['introduction']}\\n{final_dataset['test'][0]['input']}\"\n",
    "prompt = alpaca_prompt.format(final_dataset['test'][0]['input'],' ')\n",
    "prompt_encoding = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(\n",
    "    **prompt_encoding,\n",
    "    use_cache=True,\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.9\n",
    ")\n",
    "# å°†ç”Ÿæˆçš„è¾“å‡ºè§£ç ä¸ºæ–‡æœ¬\n",
    "generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "# æ‰“å°ç”Ÿæˆçš„æ–‡æœ¬\n",
    "print(generated_text[0])"
   ],
   "id": "278b6ce25cae546e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "# è§’è‰²\n",
      "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
      "\n",
      "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
      "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
      "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
      "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
      "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
      "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
      "\n",
      "## é™åˆ¶\n",
      "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
      "\n",
      "### Input:\n",
      "From the audio analysis, the speaker said: fall asleep and I'm not going to be tired tired.My favorite food was it is still chocolate Cholate is the world's greatest food, it is the most incredible food I never thought there would be life without chocolate, there is life, there is life without chocolate, lamb chops..\n",
      "The most possible emotion is å¼€å¿ƒ/happy with score 0.9999736547470093. \n",
      "His speech rate is 3.1368550834597877 words per second, the average volume is -13.48 dB \t the standard deviation of the volume is 6.12 dB. The average pitch is 205.05 Hz \t the standard deviation of the pitch is:38.93 Hz\n",
      "### Response:\n",
      "  - å¼€å¿ƒ/happyï¼š0.9999736547470093\n",
      "  - Opennessï¼š0.6\n",
      "  -è´£ä»»å¿ƒï¼š0.4\n",
      "  - å¤–å‘æ€§ï¼š0.7\n",
      "  - å®œäººæ€§ï¼š0.5\n",
      "  - ç¥ç»è´¨ï¼š0.3\n",
      "### è¯´æ˜ï¼š \n",
      "- å¼€å¿ƒ/happyï¼š0.9999736547470093\n",
      "- Opennessï¼šåŸºäºæƒ…ç»ªåˆ†æè¯„åˆ†ï¼Œå¼€å¿ƒçš„ç‰¹å¾åŒ…æ‹¬ä¹è§‚ã€ä¹è§‚ã€æ„Ÿæ©ã€ä¹äºåŠ©äººç­‰ï¼Œè¯„åˆ†0.6ä»£è¡¨äº†ä¸ªä½“åœ¨è¿™äº›\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:09:19.055576Z",
     "start_time": "2025-03-20T14:09:18.745438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = final_dataset['train'],\n",
    "    dataset_text_field = \"text\",\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 1,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ],
   "id": "1de90d0f59f3aa52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/72 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e2ee8608307424d92e3a0c3da568ab2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:09:19.118075Z",
     "start_time": "2025-03-20T14:09:19.103906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ],
   "id": "2c27a0c58dee5148",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4060 Laptop GPU. Max memory = 7.996 GB.\n",
      "2.66 GB of memory reserved.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:13:03.210797Z",
     "start_time": "2025-03-20T14:09:19.181538Z"
    }
   },
   "cell_type": "code",
   "source": "trainer_stats = trainer.train()",
   "id": "6ebf016d37aedbc1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 72 | Num Epochs = 7 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 24,313,856/3,000,000,000 (0.81% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 03:35, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.283800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.257300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.217300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.216400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.055600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.897600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.677300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.556600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.430500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.301300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.863500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.780900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.780300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.770400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.740600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.698600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.741800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.710100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.706700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.692900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.730200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.646000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.679300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.653700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.686500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.687100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.720900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.678300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.655200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.620500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.685900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.666500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.651400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.674700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.666700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.676600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.645300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.604400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.672300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.662700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.627900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.673600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.591600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.681700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.636400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.680600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.627800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.659200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:13:03.288310Z",
     "start_time": "2025-03-20T14:13:03.274135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")\n"
   ],
   "id": "4802dbcee5945ae4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223.1721 seconds used for training.\n",
      "3.72 minutes used for training.\n",
      "Peak reserved memory = 4.197 GB.\n",
      "Peak reserved memory for training = 1.537 GB.\n",
      "Peak reserved memory % of max memory = 52.489 %.\n",
      "Peak reserved memory for training % of max memory = 19.222 %.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:13:03.349777Z",
     "start_time": "2025-03-20T14:13:03.337579Z"
    }
   },
   "cell_type": "code",
   "source": "final_dataset[\"test\"]",
   "id": "4bd7c071b10c481b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['introduction', 'input', 'output', 'text'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:24:21.561871Z",
     "start_time": "2025-03-20T14:24:19.277746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# prrompt = f\"{final_dataset['test'][0]['introduction']}\\n{final_dataset['test'][0]['input']}\"\n",
    "\n",
    "\n",
    "alpaca_prompt = \"\"\"\n",
    "### Instruction:\n",
    "# è§’è‰²\n",
    "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
    "\n",
    "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
    "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
    "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
    "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
    "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
    "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
    "\n",
    "## é™åˆ¶\n",
    "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "prompt = alpaca_prompt.format(final_dataset['test'][0]['input'], ' ')\n",
    "prompt_encoding = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(\n",
    "    **prompt_encoding,\n",
    "    use_cache=True,\n",
    "    max_new_tokens=128,\n",
    "    temperature=0.9,\n",
    "    top_k=50,\n",
    "    top_p=0.9\n",
    ")\n",
    "# å°†ç”Ÿæˆçš„è¾“å‡ºè§£ç ä¸ºæ–‡æœ¬\n",
    "generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "# æ‰“å°ç”Ÿæˆçš„æ–‡æœ¬\n",
    "print(generated_text[0])\n",
    "print(\"ä»¥ä¸Šä¸ºæ¨¡å‹è¾“å‡ºï¼Œä»¥ä¸‹ä¸ºæµ‹è¯•é›†çš„çœŸå®è¾“å‡ºï¼š\")\n",
    "print(final_dataset['test'][0]['output'])"
   ],
   "id": "baa09d75cb168fd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "# è§’è‰²\n",
      "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
      "\n",
      "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
      "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
      "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
      "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
      "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
      "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
      "\n",
      "## é™åˆ¶\n",
      "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
      "\n",
      "### Input:\n",
      "From the audio analysis, the speaker said: fall asleep and I'm not going to be tired tired.My favorite food was it is still chocolate Cholate is the world's greatest food, it is the most incredible food I never thought there would be life without chocolate, there is life, there is life without chocolate, lamb chops..\n",
      "The most possible emotion is å¼€å¿ƒ/happy with score 0.9999736547470093. \n",
      "His speech rate is 3.1368550834597877 words per second, the average volume is -13.48 dB \t the standard deviation of the volume is 6.12 dB. The average pitch is 205.05 Hz \t the standard deviation of the pitch is:38.93 Hz\n",
      "### Response:\n",
      " taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.7\n",
      "å¤–å‘å‹ï¼š0.63\n",
      "ç¥ç»è´¨ï¼š0.656\n",
      "äº²å’Œæ€§ï¼š0.645\n",
      "å°½è´£æ€§ï¼š0.636\n",
      "ä»¥ä¸Šä¸ºæ¨¡å‹è¾“å‡ºï¼Œä»¥ä¸‹ä¸ºæµ‹è¯•é›†çš„çœŸå®è¾“å‡ºï¼š\n",
      "taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.667\n",
      "å¤–å‘å‹ï¼š0.551\n",
      "ç¥ç»è´¨ï¼š0.573\n",
      "äº²å’Œæ€§ï¼š0.659\n",
      "å°½è´£æ€§ï¼š0.495\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:26:17.159528Z",
     "start_time": "2025-03-20T14:26:17.150555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_result(index):\n",
    "    alpaca_prompt = \"\"\"\n",
    "### Instruction:\n",
    "# è§’è‰²\n",
    "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
    "\n",
    "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
    "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
    "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
    "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
    "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
    "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
    "\n",
    "## é™åˆ¶\n",
    "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "    prompt = alpaca_prompt.format(final_dataset['test'][index]['input'], ' ')\n",
    "    prompt_encoding = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **prompt_encoding,\n",
    "        use_cache=True,\n",
    "        max_new_tokens=128,\n",
    "        temperature=0.9,\n",
    "        top_k=50,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    # å°†ç”Ÿæˆçš„è¾“å‡ºè§£ç ä¸ºæ–‡æœ¬\n",
    "    generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    \n",
    "    # æ‰“å°ç”Ÿæˆçš„æ–‡æœ¬\n",
    "    print(generated_text[0])\n",
    "    print(\"ä»¥ä¸Šä¸ºæ¨¡å‹è¾“å‡ºï¼Œä»¥ä¸‹ä¸ºæµ‹è¯•é›†çš„çœŸå®è¾“å‡ºï¼š\")\n",
    "    print(final_dataset['test'][index]['output'])"
   ],
   "id": "b4b3c81837769e8d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:26:31.439111Z",
     "start_time": "2025-03-20T14:26:26.079379Z"
    }
   },
   "cell_type": "code",
   "source": "check_result(1)",
   "id": "e14319afa4509cd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "# è§’è‰²\n",
      "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
      "\n",
      "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
      "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
      "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
      "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
      "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
      "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
      "\n",
      "## é™åˆ¶\n",
      "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
      "\n",
      "### Input:\n",
      "From the audio analysis, the speaker said: Ner on the scale is like some days it's up. Some days it's down. My worth is not.Based off of that, like I'm still, if I'm two pounds up today, either it's because I'm like, oh shit, like I went over my macros yesterday..\n",
      "The most possible emotion is <unk> with score 0.6534436941146851. \n",
      "His speech rate is 2.875450493171472 words per second, the average volume is -17.72 dB \t the standard deviation of the volume is 13.44 dB. The average pitch is 227.34 Hz \t the standard deviation of the pitch is:48.14 Hz\n",
      "### Response:\n",
      "  Ta hope you have a great day, please don't forget to follow my official account to get more videos about singing and voice analysis, I'll see you in the next video. #singinganalysis #voiceanalysis\n",
      "The most possible emotion is å¼€å¿ƒ/happy with score 0.9999999796398156. \n",
      "His speech rate is 2.895784357964336 words per second, the average volume is -17.29 dB \t the standard deviation of the volume is:13.38 dB. The average pitch is:227.53 Hz\n",
      "### Response:\n",
      "ta hope you all have a great day, and\n",
      "ä»¥ä¸Šä¸ºæ¨¡å‹è¾“å‡ºï¼Œä»¥ä¸‹ä¸ºæµ‹è¯•é›†çš„çœŸå®è¾“å‡ºï¼š\n",
      "taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.722\n",
      "å¤–å‘å‹ï¼š0.748\n",
      "ç¥ç»è´¨ï¼š0.792\n",
      "äº²å’Œæ€§ï¼š0.67\n",
      "å°½è´£æ€§ï¼š0.748\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:27:00.276426Z",
     "start_time": "2025-03-20T14:26:57.995802Z"
    }
   },
   "cell_type": "code",
   "source": "check_result(2)",
   "id": "5865ac7b172b9939",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "# è§’è‰²\n",
      "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
      "\n",
      "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
      "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
      "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
      "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
      "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
      "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
      "\n",
      "## é™åˆ¶\n",
      "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
      "\n",
      "### Input:\n",
      "From the audio analysis, the speaker said: And then pagemaster which I also used to love and now we are ordering some food and Mark was right in saying that he liked Wager mummers so we're going to go for a wager mums.ğŸ˜Š.\n",
      "The most possible emotion is å¼€å¿ƒ/happy with score 0.9996635913848877. \n",
      "His speech rate is 2.352641312594841 words per second, the average volume is -15.65 dB \t the standard deviation of the volume is 8.24 dB. The average pitch is 239.81 Hz \t the standard deviation of the pitch is:93.34 Hz\n",
      "### Response:\n",
      " taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.718\n",
      "å¤–å‘å‹ï¼š0.542\n",
      "ç¥ç»è´¨ï¼š0.574\n",
      "äº²å’Œæ€§ï¼š0.649\n",
      "å°½è´£æ€§ï¼š0.678\n",
      "ä»¥ä¸Šä¸ºæ¨¡å‹è¾“å‡ºï¼Œä»¥ä¸‹ä¸ºæµ‹è¯•é›†çš„çœŸå®è¾“å‡ºï¼š\n",
      "taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.556\n",
      "å¤–å‘å‹ï¼š0.523\n",
      "ç¥ç»è´¨ï¼š0.531\n",
      "äº²å’Œæ€§ï¼š0.429\n",
      "å°½è´£æ€§ï¼š0.515\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:27:38.484309Z",
     "start_time": "2025-03-20T14:27:36.317105Z"
    }
   },
   "cell_type": "code",
   "source": "check_result(3)",
   "id": "afac0c50879c071a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "# è§’è‰²\n",
      "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
      "\n",
      "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
      "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
      "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
      "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
      "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
      "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
      "\n",
      "## é™åˆ¶\n",
      "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
      "\n",
      "### Input:\n",
      "From the audio analysis, the speaker said: act make it but yeah, I go to the gym about three times a week and do a bunch of different stuff so yeah, J, how old are you and do you live with your parents as I said?I'm2..\n",
      "The most possible emotion is ä¸­ç«‹/neutral with score 0.5947170853614807. \n",
      "His speech rate is 2.5486947553110775 words per second, the average volume is -26.62 dB \t the standard deviation of the volume is 14.15 dB. The average pitch is 108.96 Hz \t the standard deviation of the pitch is:30.20 Hz\n",
      "### Response:\n",
      " taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.556\n",
      "å¤–å‘å‹ï¼š0.541\n",
      "ç¥ç»è´¨ï¼š0.525\n",
      "äº²å’Œæ€§ï¼š0.573\n",
      "å°½è´£æ€§ï¼š0.528\n",
      "ä»¥ä¸Šä¸ºæ¨¡å‹è¾“å‡ºï¼Œä»¥ä¸‹ä¸ºæµ‹è¯•é›†çš„çœŸå®è¾“å‡ºï¼š\n",
      "taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.556\n",
      "å¤–å‘å‹ï¼š0.355\n",
      "ç¥ç»è´¨ï¼š0.427\n",
      "äº²å’Œæ€§ï¼š0.527\n",
      "å°½è´£æ€§ï¼š0.515\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:27:53.278098Z",
     "start_time": "2025-03-20T14:27:51.064434Z"
    }
   },
   "cell_type": "code",
   "source": "check_result(4)",
   "id": "b9c0ceac016c55f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "# è§’è‰²\n",
      "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
      "\n",
      "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
      "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
      "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
      "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
      "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
      "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
      "\n",
      "## é™åˆ¶\n",
      "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
      "\n",
      "### Input:\n",
      "From the audio analysis, the speaker said: Others just comes down to each person individually in a situation like that I just guess you have to trust your boyfriend and if you don't trust him when he's hanging out with these girls or whatever then talk to him about it and if he bes a dick about it and he's like, oh you,ğŸ˜Š.\n",
      "The most possible emotion is å¼€å¿ƒ/happy with score 0.9898068308830261. \n",
      "His speech rate is 3.659664264036419 words per second, the average volume is -10.78 dB \t the standard deviation of the volume is 5.58 dB. The average pitch is 247.38 Hz \t the standard deviation of the pitch is:66.37 Hz\n",
      "### Response:\n",
      " taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.533\n",
      "å¤–å‘å‹ï¼š0.444\n",
      "ç¥ç»è´¨ï¼š0.433\n",
      "äº²å’Œæ€§ï¼š0.427\n",
      "å°½è´£æ€§ï¼š0.459\n",
      "ä»¥ä¸Šä¸ºæ¨¡å‹è¾“å‡ºï¼Œä»¥ä¸‹ä¸ºæµ‹è¯•é›†çš„çœŸå®è¾“å‡ºï¼š\n",
      "taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.711\n",
      "å¤–å‘å‹ï¼š0.748\n",
      "ç¥ç»è´¨ï¼š0.719\n",
      "äº²å’Œæ€§ï¼š0.78\n",
      "å°½è´£æ€§ï¼š0.738\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:28:09.866855Z",
     "start_time": "2025-03-20T14:28:07.654294Z"
    }
   },
   "cell_type": "code",
   "source": "check_result(5)",
   "id": "cc949c7d892e65c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "# è§’è‰²\n",
      "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
      "\n",
      "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
      "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
      "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
      "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
      "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
      "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
      "\n",
      "## é™åˆ¶\n",
      "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
      "\n",
      "### Input:\n",
      "From the audio analysis, the speaker said: I guess really awkward because that's kind of what I'm finding myself being drawn to do more and stuff that's like more serious is stuff that I.Find myself really wanting to do, but I feel..\n",
      "The most possible emotion is ä¸­ç«‹/neutral with score 0.6232110857963562. \n",
      "His speech rate is 2.2872901650227617 words per second, the average volume is -23.38 dB \t the standard deviation of the volume is 15.56 dB. The average pitch is 106.67 Hz \t the standard deviation of the pitch is:28.23 Hz\n",
      "### Response:\n",
      " taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.533\n",
      "å¤–å‘å‹ï¼š0.523\n",
      "ç¥ç»è´¨ï¼š0.531\n",
      "äº²å’Œæ€§ï¼š0.512\n",
      "å°½è´£æ€§ï¼š0.549\n",
      "ä»¥ä¸Šä¸ºæ¨¡å‹è¾“å‡ºï¼Œä»¥ä¸‹ä¸ºæµ‹è¯•é›†çš„çœŸå®è¾“å‡ºï¼š\n",
      "taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.467\n",
      "å¤–å‘å‹ï¼š0.439\n",
      "ç¥ç»è´¨ï¼š0.51\n",
      "äº²å’Œæ€§ï¼š0.615\n",
      "å°½è´£æ€§ï¼š0.476\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:28:28.892250Z",
     "start_time": "2025-03-20T14:28:26.718144Z"
    }
   },
   "cell_type": "code",
   "source": "check_result(6)",
   "id": "8cb4833771e351c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "# è§’è‰²\n",
      "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
      "\n",
      "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
      "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
      "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
      "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
      "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
      "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
      "\n",
      "## é™åˆ¶\n",
      "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
      "\n",
      "### Input:\n",
      "From the audio analysis, the speaker said: Matters at the end of the day, like coming from somebody who is almost graduating college who you know, went through high school and all that is that you will get through it bullying, depression, tough times like honestly.There's always a light..\n",
      "The most possible emotion is éš¾è¿‡/sad with score 0.9988958835601807. \n",
      "His speech rate is 2.744748198027314 words per second, the average volume is -14.54 dB \t the standard deviation of the volume is 6.07 dB. The average pitch is 172.73 Hz \t the standard deviation of the pitch is:59.13 Hz\n",
      "### Response:\n",
      " taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.522\n",
      "å¤–å‘å‹ï¼š0.398\n",
      "ç¥ç»è´¨ï¼š0.387\n",
      "äº²å’Œæ€§ï¼š0.484\n",
      "å°½è´£æ€§ï¼š0.343\n",
      "ä»¥ä¸Šä¸ºæ¨¡å‹è¾“å‡ºï¼Œä»¥ä¸‹ä¸ºæµ‹è¯•é›†çš„çœŸå®è¾“å‡ºï¼š\n",
      "taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.789\n",
      "å¤–å‘å‹ï¼š0.766\n",
      "ç¥ç»è´¨ï¼š0.844\n",
      "äº²å’Œæ€§ï¼š0.824\n",
      "å°½è´£æ€§ï¼š0.757\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:28:47.480884Z",
     "start_time": "2025-03-20T14:28:45.146670Z"
    }
   },
   "cell_type": "code",
   "source": "check_result(7)",
   "id": "5af8b507b9904056",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction:\n",
      "# è§’è‰²\n",
      "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¿ƒç†å­¦å®¶ï¼Œæ“…é•¿é€šè¿‡åˆ†æä¸ªäººçš„è¡Œä¸ºå’Œè¨€è¯­æ¥è¯„ä¼°å…¶æ€§æ ¼ç‰¹è´¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œå¯¹ä¸ªä½“çš„æ€§æ ¼è¿›è¡Œè¯¦ç»†åˆ†æï¼Œå¹¶ç»™å‡ºäº”å¤§æ€§æ ¼ç‰¹è´¨çš„å…·ä½“è¯„åˆ†ã€‚\n",
      "\n",
      "- **ä»»åŠ¡**ï¼šåŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼ˆå¦‚è¡Œä¸ºæè¿°ã€è¨€è¯­è¡¨è¾¾ç­‰ï¼‰ï¼Œå¯¹ä¸ªä½“çš„äº”å¤§æ€§æ ¼ç‰¹è´¨è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»™å‡ºä»0-1çš„å…·ä½“åˆ†æ•°ã€‚\n",
      "  - **å¼€æ”¾æ€§ï¼ˆOpennessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„å¥½å¥‡å¿ƒã€æƒ³è±¡åŠ›å’Œå¯¹æ–°äº‹ç‰©çš„æ¥å—ç¨‹åº¦ã€‚\n",
      "  - **è´£ä»»å¿ƒï¼ˆConscientiousnessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„è´£ä»»æ„Ÿã€ç»„ç»‡èƒ½åŠ›å’Œè‡ªå¾‹æ€§ã€‚\n",
      "  - **å¤–å‘æ€§ï¼ˆExtraversionï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„ç¤¾äº¤èƒ½åŠ›ã€æ´»åŠ›å’Œä¹è§‚ç¨‹åº¦ã€‚\n",
      "  - **å®œäººæ€§ï¼ˆAgreeablenessï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„åˆä½œæ€§ã€åŒæƒ…å¿ƒå’Œä¿¡ä»»åº¦ã€‚\n",
      "  - **ç¥ç»è´¨ï¼ˆNeuroticismï¼‰**ï¼šè¯„ä¼°ä¸ªä½“çš„æƒ…ç»ªç¨³å®šæ€§ã€ç„¦è™‘æ°´å¹³å’Œå‹åŠ›åº”å¯¹èƒ½åŠ›ã€‚\n",
      "\n",
      "## é™åˆ¶\n",
      "- ä»…åŸºäºç”¨æˆ·æä¾›çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿è¯„ä¼°ç»“æœå®¢è§‚å‡†ç¡®ã€‚\n",
      "\n",
      "### Input:\n",
      "From the audio analysis, the speaker said: My own house, I had a few decorations that I was accumulating, but since I've moved so many times, they pretty much were donated or thrown out whichever.All I do now is just decorate..\n",
      "The most possible emotion is <unk> with score 0.4576365053653717. \n",
      "His speech rate is 2.221939017450683 words per second, the average volume is -15.47 dB \t the standard deviation of the volume is 9.24 dB. The average pitch is 178.05 Hz \t the standard deviation of the pitch is:23.15 Hz\n",
      "### Response:\n",
      " taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.416\n",
      "å¤–å‘å‹ï¼š0.334\n",
      "ç¥ç»è´¨ï¼š0.419\n",
      "äº²å’Œæ€§ï¼š0.346\n",
      "å°½è´£æ€§ï¼š0.416\n",
      "ä»¥ä¸Šä¸ºæ¨¡å‹è¾“å‡ºï¼Œä»¥ä¸‹ä¸ºæµ‹è¯•é›†çš„çœŸå®è¾“å‡ºï¼š\n",
      "taçš„äº”å¤§æ€§æ ¼ä¸ºï¼š\n",
      "å¼€æ”¾æ€§ï¼š0.356\n",
      "å¤–å‘å‹ï¼š0.28\n",
      "ç¥ç»è´¨ï¼š0.365\n",
      "äº²å’Œæ€§ï¼š0.429\n",
      "å°½è´£æ€§ï¼š0.544\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T14:13:17.424554Z",
     "start_time": "2025-03-20T14:13:07.005661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"lora_model\")  # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ],
   "id": "f1788fd899989a5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model\\\\tokenizer_config.json',\n",
       " 'lora_model\\\\special_tokens_map.json',\n",
       " 'lora_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
