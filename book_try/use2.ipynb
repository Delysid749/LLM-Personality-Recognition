{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-13T08:30:54.947454Z",
     "start_time": "2025-03-13T08:30:54.456475Z"
    }
   },
   "source": [
    "import re\n",
    "import json\n",
    "from urllib import request\n",
    "from http import HTTPStatus\n",
    "import dashscope\n",
    "\n",
    "api_key = \"sk-8ac1a297ccc9487cafcf22a43bc8c4b8\"\n",
    "\n",
    "audio_dir = r\"E:\\code\\project\\data\\voice\\\\\"\n",
    "audio_file_list =[\"1DCnIad1Y0w.002.mp3\",\"9mM_0vrO3wc.003.mp3\"]\n",
    "audio_path = audio_dir + audio_file_list[1]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T08:38:29.522364Z",
     "start_time": "2025-03-13T08:38:26.411251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将your-dashscope-api-key替换成您自己的API-KEY\n",
    "dashscope.api_key =api_key\n",
    "\n",
    "def parse_sensevoice_result(data, keep_trans=True, keep_emotions=True, keep_events=True):\n",
    "    '''\n",
    "    本工具用于解析 sensevoice 识别结果\n",
    "    keep_trans: 是否保留转写文本，默认为True\n",
    "    keep_emotions: 是否保留情感标签，默认为True\n",
    "    keep_events: 是否保留事件标签，默认为True\n",
    "    '''\n",
    "    # 定义要保留的标签\n",
    "    emotion_list = ['NEUTRAL', 'HAPPY', 'ANGRY', 'SAD']\n",
    "    event_list = ['Speech', 'Applause', 'BGM', 'Laughter']\n",
    "\n",
    "    # 所有支持的标签\n",
    "    all_tags = ['Speech', 'Applause', 'BGM', 'Laughter',\n",
    "                'NEUTRAL', 'HAPPY', 'ANGRY', 'SAD', 'SPECIAL_TOKEN_1']\n",
    "    tags_to_cleanup = []\n",
    "    for tag in all_tags:\n",
    "        tags_to_cleanup.append(f'<|{tag}|> ')\n",
    "        tags_to_cleanup.append(f'<|/{tag}|>')\n",
    "        tags_to_cleanup.append(f'<|{tag}|>')\n",
    "\n",
    "    def get_clean_text(text: str):\n",
    "        for tag in tags_to_cleanup:\n",
    "            text = text.replace(tag, '')\n",
    "        pattern = r\"\\s{2,}\"\n",
    "        text = re.sub(pattern, \" \", text).strip()\n",
    "        return text\n",
    "\n",
    "    for item in data['transcripts']:\n",
    "        for sentence in item['sentences']:\n",
    "            if keep_emotions:\n",
    "                # 提取 emotion\n",
    "                emotions_pattern = r'<\\|(' + '|'.join(emotion_list) + r')\\|>'\n",
    "                emotions = re.findall(emotions_pattern, sentence['text'])\n",
    "                sentence['emotion'] = list(set(emotions))\n",
    "                if not sentence['emotion']:\n",
    "                    sentence.pop('emotion', None)\n",
    "\n",
    "            if keep_events:\n",
    "                # 提取 event\n",
    "                events_pattern = r'<\\|(' + '|'.join(event_list) + r')\\|>'\n",
    "                events = re.findall(events_pattern, sentence['text'])\n",
    "                sentence['event'] = list(set(events))\n",
    "                if not sentence['event']:\n",
    "                    sentence.pop('event', None)\n",
    "\n",
    "            if keep_trans:\n",
    "                # 提取纯文本\n",
    "                sentence['text'] = get_clean_text(sentence['text'])\n",
    "            else:\n",
    "                sentence.pop('text', None)\n",
    "\n",
    "        if keep_trans:\n",
    "            item['text'] = get_clean_text(item['text'])\n",
    "        else:\n",
    "            item.pop('text', None)\n",
    "        item['sentences'] = list(filter(lambda x: 'text' in x or 'emotion' in x or 'event' in x, item['sentences']))\n",
    "    return data\n",
    "\n",
    "\n",
    "task_response = dashscope.audio.asr.Transcription.async_call(\n",
    "    model='sensevoice-v1',\n",
    "    file_urls=[\n",
    "        'https://dashscope.oss-cn-beijing.aliyuncs.com/samples/audio/sensevoice/rich_text_example_1.wav'],\n",
    "    language_hints=['en'], )\n",
    "\n",
    "print('task_id: ', task_response.output.task_id)\n",
    "\n",
    "transcription_response = dashscope.audio.asr.Transcription.wait(\n",
    "    task=task_response.output.task_id)\n",
    "\n",
    "if transcription_response.status_code == HTTPStatus.OK:\n",
    "    for transcription in transcription_response.output['results']:\n",
    "        if transcription['subtask_status'] == 'SUCCEEDED':\n",
    "            url = transcription['transcription_url']\n",
    "            result = json.loads(request.urlopen(url).read().decode('utf8'))\n",
    "            print(json.dumps(parse_sensevoice_result(result, keep_trans=False, keep_emotions=False), indent=4,\n",
    "                            ensure_ascii=False))\n",
    "        else:\n",
    "            print('transcription failed!')\n",
    "            print(transcription)\n",
    "    print('transcription done!')\n",
    "else:\n",
    "    print('Error: ', transcription_response.output.message)"
   ],
   "id": "92b3d034a3d58ea3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id:  d16947da-690d-4fb3-bf4e-3fd74c1a4d01\n",
      "{\n",
      "    \"file_url\": \"https://dashscope.oss-cn-beijing.aliyuncs.com/samples/audio/sensevoice/rich_text_example_1.wav\",\n",
      "    \"properties\": {\n",
      "        \"audio_format\": \"pcm_s16le\",\n",
      "        \"channels\": [\n",
      "            0\n",
      "        ],\n",
      "        \"original_sampling_rate\": 16000,\n",
      "        \"original_duration_in_milliseconds\": 17645\n",
      "    },\n",
      "    \"transcripts\": [\n",
      "        {\n",
      "            \"channel_id\": 0,\n",
      "            \"content_duration_in_milliseconds\": 13240,\n",
      "            \"sentences\": [\n",
      "                {\n",
      "                    \"begin_time\": 0,\n",
      "                    \"end_time\": 7480,\n",
      "                    \"event\": [\n",
      "                        \"Speech\"\n",
      "                    ]\n",
      "                },\n",
      "                {\n",
      "                    \"begin_time\": 11880,\n",
      "                    \"end_time\": 17640,\n",
      "                    \"event\": [\n",
      "                        \"Speech\",\n",
      "                        \"Applause\"\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "transcription done!\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
